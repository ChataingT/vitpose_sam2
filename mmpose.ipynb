{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import mimetypes\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import cv2\n",
    "import json_tricks as json\n",
    "import mmcv\n",
    "import mmengine\n",
    "import numpy as np\n",
    "from mmengine.logging import print_log\n",
    "\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.apis import init_model as init_pose_estimator\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "\n",
    "# try:\n",
    "    # from mmdet.apis import inference_detector, init_detector\n",
    "    # has_mmdet = True\n",
    "# except (ImportError, ModuleNotFoundError):\n",
    "    # has_mmdet = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(line_argument=None):\n",
    "    \"\"\"Visualize the demo images.\n",
    "\n",
    "    Using mmdet to detect the human.\n",
    "    \"\"\"\n",
    "    parser = ArgumentParser()\n",
    "    # parser.add_argument('det_config', help='Config file for detection')\n",
    "    # parser.add_argument('det_checkpoint', help='Checkpoint file for detection')\n",
    "    parser.add_argument('pose_config', help='Config file for pose')\n",
    "    parser.add_argument('pose_checkpoint', help='Checkpoint file for pose')\n",
    "    parser.add_argument(\n",
    "        '--input', type=str, default='', help='Image/Video file')\n",
    "    parser.add_argument(\n",
    "        '--show',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='whether to show img')\n",
    "    parser.add_argument(\n",
    "        '--output-root',\n",
    "        type=str,\n",
    "        default='',\n",
    "        help='root of the output img file. '\n",
    "        'Default not saving the visualization images.')\n",
    "    parser.add_argument(\n",
    "        '--save-predictions',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='whether to save predicted results')\n",
    "    parser.add_argument(\n",
    "        '--device', default='cuda:0', help='Device used for inference')\n",
    "    parser.add_argument(\n",
    "        '--det-cat-id',\n",
    "        type=int,\n",
    "        default=0,\n",
    "        help='Category id for bounding box detection model')\n",
    "    parser.add_argument(\n",
    "        '--bbox-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Bounding box score threshold')\n",
    "    parser.add_argument(\n",
    "        '--nms-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='IoU threshold for bounding box NMS')\n",
    "    parser.add_argument(\n",
    "        '--kpt-thr',\n",
    "        type=float,\n",
    "        default=0.3,\n",
    "        help='Visualizing keypoint thresholds')\n",
    "    parser.add_argument(\n",
    "        '--draw-heatmap',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='Draw heatmap predicted by the model')\n",
    "    parser.add_argument(\n",
    "        '--show-kpt-idx',\n",
    "        action='store_true',\n",
    "        default=False,\n",
    "        help='Whether to show the index of keypoints')\n",
    "    parser.add_argument(\n",
    "        '--skeleton-style',\n",
    "        default='mmpose',\n",
    "        type=str,\n",
    "        choices=['mmpose', 'openpose'],\n",
    "        help='Skeleton style selection')\n",
    "    parser.add_argument(\n",
    "        '--radius',\n",
    "        type=int,\n",
    "        default=3,\n",
    "        help='Keypoint radius for visualization')\n",
    "    parser.add_argument(\n",
    "        '--thickness',\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help='Link thickness for visualization')\n",
    "    parser.add_argument(\n",
    "        '--show-interval', type=int, default=0, help='Sleep seconds per frame')\n",
    "    parser.add_argument(\n",
    "        '--alpha', type=float, default=0.8, help='The transparency of bboxes')\n",
    "    parser.add_argument(\n",
    "        '--draw-bbox', action='store_true', help='Draw bboxes of instances')\n",
    "    \n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--bboxes', type=str, help='Path to the json file which contains the bbox')\n",
    "\n",
    "    # assert has_mmdet, 'Please install mmdet to run the demo.'\n",
    "\n",
    "    args = parser.parse_args(line_argument)\n",
    "\n",
    "    assert args.show or (args.output_root != '')\n",
    "    assert args.input != ''\n",
    "    # assert args.det_config is not None\n",
    "    # assert args.det_checkpoint is not None\n",
    "\n",
    "    output_file = None\n",
    "    if args.output_root:\n",
    "        mmengine.mkdir_or_exist(args.output_root)\n",
    "        output_file = os.path.join(args.output_root,\n",
    "                                   os.path.basename(args.input))\n",
    "        if args.input == 'webcam':\n",
    "            output_file += '.mp4'\n",
    "\n",
    "    if args.save_predictions:\n",
    "        assert args.output_root != ''\n",
    "        args.pred_save_path = f'{args.output_root}/results_' \\\n",
    "            f'{os.path.splitext(os.path.basename(args.input))[0]}.json'\n",
    "\n",
    "    # build detector\n",
    "    # detector = init_detector(\n",
    "    #     args.det_config, args.det_checkpoint, device=args.device)\n",
    "    # detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "    with open(args.bboxes, 'r') as fd:\n",
    "        bboxes = json.load(fd)\n",
    "\n",
    "    # build pose estimator\n",
    "    pose_estimator = init_pose_estimator(\n",
    "        args.pose_config,\n",
    "        args.pose_checkpoint,\n",
    "        device=args.device,\n",
    "        cfg_options=dict(\n",
    "            model=dict(test_cfg=dict(output_heatmaps=args.draw_heatmap))))\n",
    "\n",
    "    # build visualizer\n",
    "    pose_estimator.cfg.visualizer.radius = args.radius\n",
    "    pose_estimator.cfg.visualizer.alpha = args.alpha\n",
    "    pose_estimator.cfg.visualizer.line_width = args.thickness\n",
    "    visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)\n",
    "    # the dataset_meta is loaded from the checkpoint and\n",
    "    # then pass to the model in init_pose_estimator\n",
    "    visualizer.set_dataset_meta(\n",
    "        pose_estimator.dataset_meta, skeleton_style=args.skeleton_style)\n",
    "\n",
    "    if args.input == 'webcam':\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # input_type = 'webcam'\n",
    "    else:\n",
    "        input_type = mimetypes.guess_type(args.input)[0].split('/')[0]\n",
    "\n",
    "    if input_type == 'image':\n",
    "        raise NotImplementedError\n",
    "        # inference\n",
    "        # pred_instances = process_one_image(args, args.input, bboxes,\n",
    "        #                                    pose_estimator, visualizer)\n",
    "\n",
    "        # if args.save_predictions:\n",
    "        #     pred_instances_list = split_instances(pred_instances)\n",
    "\n",
    "        # if output_file:\n",
    "        #     img_vis = visualizer.get_image()\n",
    "        #     mmcv.imwrite(mmcv.rgb2bgr(img_vis), output_file)\n",
    "\n",
    "    elif input_type in ['webcam', 'video']:\n",
    "\n",
    "        if args.input == 'webcam':\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(args.input)\n",
    "\n",
    "        video_writer = None\n",
    "        pred_instances_list = []\n",
    "        frame_idx = 0\n",
    "\n",
    "        pbar = tqdm(desc='mmpose in progress', total=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "        while cap.isOpened():\n",
    "            success, frame = cap.read()\n",
    "\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            # topdown pose estimation\n",
    "            pred_instances = process_one_image(args, frame, bboxes[str(frame_idx)],\n",
    "                                               pose_estimator, visualizer,\n",
    "                                               0.001)\n",
    "\n",
    "            if args.save_predictions:\n",
    "                # save prediction results\n",
    "                pred_instances_list.append(\n",
    "                    dict(\n",
    "                        frame_id=frame_idx,\n",
    "                        instances=split_instances(pred_instances)))\n",
    "\n",
    "            # output videos\n",
    "            if output_file:\n",
    "                frame_vis = visualizer.get_image()\n",
    "\n",
    "                if video_writer is None:\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "                    # the size of the image with visualization may vary\n",
    "                    # depending on the presence of heatmaps\n",
    "                    video_writer = cv2.VideoWriter(\n",
    "                        output_file,\n",
    "                        fourcc,\n",
    "                        30,  # saved fps\n",
    "                        (frame_vis.shape[1], frame_vis.shape[0]))\n",
    "\n",
    "                video_writer.write(mmcv.rgb2bgr(frame_vis))\n",
    "\n",
    "            if args.show:\n",
    "                # press ESC to exit\n",
    "                if cv2.waitKey(5) & 0xFF == 27:\n",
    "                    break\n",
    "\n",
    "                time.sleep(args.show_interval)\n",
    "            frame_idx += 1\n",
    "\n",
    "            pbar.update()\n",
    "            \n",
    "\n",
    "        if video_writer:\n",
    "            video_writer.release()\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    else:\n",
    "        args.save_predictions = False\n",
    "        raise ValueError(\n",
    "            f'file {os.path.basename(args.input)} has invalid format.')\n",
    "\n",
    "    if args.save_predictions:\n",
    "        with open(args.pred_save_path, 'w') as f:\n",
    "            json.dump(\n",
    "                dict(\n",
    "                    meta_info=pose_estimator.dataset_meta,\n",
    "                    instance_info=pred_instances_list),\n",
    "                f,\n",
    "                indent='\\t')\n",
    "        print(f'predictions have been saved at {args.pred_save_path}')\n",
    "\n",
    "    if output_file:\n",
    "        input_type = input_type.replace('webcam', 'video')\n",
    "        print_log(\n",
    "            f'the output {input_type} has been saved at {output_file}',\n",
    "            logger='current',\n",
    "            level=logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_image(args,\n",
    "                      img,\n",
    "                      bboxe,\n",
    "                      pose_estimator,\n",
    "                      visualizer=None,\n",
    "                      show_interval=0):\n",
    "    \"\"\"Visualize predicted keypoints (and heatmaps) of one image.\"\"\"\n",
    "\n",
    "    # predict bbox\n",
    "    # det_result = inference_detector(detector, img)\n",
    "    # pred_instance = det_result.pred_instances.cpu().numpy()\n",
    "    # bboxes = np.concatenate(\n",
    "        # (pred_instance.bboxes, pred_instance.scores[:, None]), axis=1)\n",
    "    # bboxes = bboxes[np.logical_and(pred_instance.labels == args.det_cat_id,\n",
    "                                #    pred_instance.scores > args.bbox_thr)]\n",
    "    # bboxes = bboxes[nms(bboxes, args.nms_thr), :4]\n",
    "    \n",
    "    height, width, _ = img.shape\n",
    "    bbox_index_mapping = {i: key for i, key in enumerate(bboxe.keys())}\n",
    "    bboxes = []\n",
    "    bboxs_label = []\n",
    "    for key in bboxe.keys():\n",
    "        bboxes.append([int(bboxe[key][0]*width), int(bboxe[key][1]*height), int(bboxe[key][2]*width), int(bboxe[key][3]*height)])\n",
    "        bboxs_label.append(key)\n",
    "    bboxes = np.array(bboxes, dtype=np.int16)\n",
    "    bboxs_label = np.array(bboxs_label, dtype=np.int16)\n",
    "    # predict keypoints\n",
    "    pose_results = inference_topdown(pose_estimator, img, bboxes)\n",
    "    data_samples = merge_data_samples(pose_results)\n",
    "\n",
    "    # add keypoints label \n",
    "    pred_inst = data_samples.get('pred_instances', None)\n",
    "\n",
    "    # Sometime we don't have bbox but the model still put one and it needs to be handle\n",
    "    if len(bboxs_label) != len(pred_inst.get('bbox_scores')):\n",
    "        bboxs_label = np.ones(pred_inst.get('bbox_scores').shape) *-1    \n",
    "        \n",
    "    pred_inst.set_data({'keypoints_label': bboxs_label})\n",
    "\n",
    "    # show the results\n",
    "    if isinstance(img, str):\n",
    "        img = mmcv.imread(img, channel_order='rgb')\n",
    "    elif isinstance(img, np.ndarray):\n",
    "        img = mmcv.bgr2rgb(img)\n",
    "\n",
    "    if visualizer is not None:\n",
    "        visualizer.add_datasample(\n",
    "            'result',\n",
    "            img,\n",
    "            data_sample=data_samples,\n",
    "            draw_gt=False,\n",
    "            draw_heatmap=args.draw_heatmap,\n",
    "            draw_bbox=args.draw_bbox,\n",
    "            show_kpt_idx=args.show_kpt_idx,\n",
    "            skeleton_style=args.skeleton_style,\n",
    "            show=args.show,\n",
    "            wait_time=show_interval,\n",
    "            kpt_thr=args.kpt_thr)\n",
    "\n",
    "    # if there is no instance detected, return None\n",
    "    return data_samples.get('pred_instances', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg=[\n",
    "    r\"D:\\idtracking\\vitpose_sam2\\mmpose\\configs\\body_2d_keypoint\\topdown_heatmap\\coco\\td-hm_ViTPose-huge_8xb64-210e_coco-256x192.py\",\n",
    "     r\"D:\\idtracking\\weights_config\\td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\",\n",
    "    \"--input\", r\"D:\\idtracking\\data\\video\\7965_T2a_ADOS_25fps.mp4\",\n",
    "    \"--bboxes\", r\"D:\\idtracking\\data\\video\\7965_T2a_ADOS_25fps\\bbox.json\",\n",
    "    \"--output-root\", r\"D:\\idtracking\\data\\video\\7965_T2a_ADOS_25fps\",\n",
    "    \"--device\", \"cuda\",\n",
    "    # \"--radius\", \"2\",\n",
    "    # \"--thickness\", \"1\",\n",
    "    \"--skeleton-style\", \"openpose\",\n",
    "    \"--save-predictions\",\n",
    "    # \"--draw-bbox\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: D:\\idtracking\\weights_config\\td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: backbone.cls_token\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chataint\\AppData\\Local\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmpose\\datasets\\datasets\\utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco_openpose.py\" does not exist. A matched config file \"c:\\Users\\chataint\\AppData\\Local\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmpose\\.mim\\configs\\_base_\\datasets\\coco_openpose.py\" will be used instead.\n",
      "  warnings.warn(\n",
      "mmpose in progress:  38%|███▊      | 31527/82066 [5:26:16<9:52:45,  1.42it/s] "
     ]
    }
   ],
   "source": [
    "main(arg)\n",
    "\n",
    "# TODO mapping bbox with id from sam2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads checkpoint by local backend from path: D:\\idtracking\\weights_config\\td-hm_ViTPose-huge_8xb64-210e_coco-256x192-e32adcd4_20230314.pth\n",
    "The model and loaded state dict do not match exactly\n",
    "\n",
    "unexpected key in source state_dict: backbone.cls_token\n",
    "\n",
    "c:\\Users\\chataint\\AppData\\Local\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmpose\\datasets\\datasets\\utils.py:102: UserWarning: The metainfo config file \"configs/_base_/datasets/coco_openpose.py\" does not exist. A matched config file \"c:\\Users\\chataint\\AppData\\Local\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmpose\\.mim\\configs\\_base_\\datasets\\coco_openpose.py\" will be used instead.\n",
    "  warnings.warn(\n",
    "mmpose in progress:  32%|███▏      | 26553/82066 [5:25:55<12:25:27,  1.24it/s]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
